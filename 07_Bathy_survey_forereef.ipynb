{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adde14b-765f-4bd5-8113-3aadac72051a",
   "metadata": {},
   "source": [
    "# Bathymetry\n",
    "\n",
    "Sample data: </br>\n",
    "Single beam echo sounder data collected from the eastern forereef of One Tree Island on 23/03/2025 by Lachlan Perris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bff5ac-a935-4e60-89e7-c55fbd45e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b42cb0-462d-4656-9b20-6d65f4c9e46b",
   "metadata": {},
   "source": [
    "# Load raw data from the instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192b480-6f6a-48d2-bd52-827d851c89b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "#df = pd.read_csv(f'250323_Bathy_survey_forereef.csv')\n",
    "df = pd.read_csv(f'data/250323_forereef_survey_clip.csv')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee7c7-0191-4433-8e1d-e9d7f85728f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['Depth_applied_elevation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd72440-7cbc-4a78-bb3b-033644cbdc18",
   "metadata": {},
   "source": [
    "### Still quite messy !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464cee4-2c91-4cef-9dbc-de2ccb9a34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install geopandas folium\n",
    "\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "# --- Inputs ---\n",
    "# df: pandas DataFrame with 'eastings', 'northings', 'Depth applied elevation' (not used for colour)\n",
    "SOURCE_EPSG = 28356  # change to your GDA94/MGA zone (e.g., 28355 or 28357)\n",
    "\n",
    "# GeoDataFrame (projected) → WGS84 for web maps\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df.copy(),\n",
    "    geometry=gpd.points_from_xy(df['East'], df['North']),\n",
    "    crs=f\"EPSG:{SOURCE_EPSG}\"\n",
    ").to_crs(epsg=4326)\n",
    "\n",
    "# Map centred on data\n",
    "centre = [gdf.geometry.y.mean(), gdf.geometry.x.mean()]\n",
    "m = folium.Map(location=centre, zoom_start=12, tiles='CartoDB Positron')\n",
    "\n",
    "# Simple points\n",
    "for pt in gdf.geometry:\n",
    "    folium.CircleMarker(\n",
    "        location=[pt.y, pt.x],\n",
    "        radius=3,   # tweak if needed\n",
    "        fill=True,\n",
    "        fill_opacity=0.9,\n",
    "        weight=0\n",
    "    ).add_to(m)\n",
    "\n",
    "# In Jupyter, just display `m`; or save to file:\n",
    "# m.save('points_map.html')\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392dd35-8e01-4666-b101-886648fa19f3",
   "metadata": {},
   "source": [
    "# Bathymetry despiking & smoothing (0.5 m sampling)\n",
    "\n",
    "**Goal:** Clean a 0.5 m–spaced bathymetry profile by removing impulsive spikes and lightly smoothing noise, while preserving genuine seabed features.\n",
    "\n",
    "---\n",
    "\n",
    "## Method\n",
    "1. **Median filter (despike)**  \n",
    "   - `window_size = 3` → spans **1.5 m**.  \n",
    "   - Replaces each value with the **median** of its neighbourhood. Robust to outliers (bad pings, bubbles), preserves sharp breaks.\n",
    "\n",
    "2. **Rolling mean (smooth)**  \n",
    "   - `rolling_window = 3` → spans **1.5 m**.  \n",
    "   - Reduces residual high-frequency jitter; `center=True` avoids lateral shift.\n",
    "\n",
    "3. **Plot**  \n",
    "   - Visualise `depth_smoothed` to confirm noise reduction and feature retention.\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters used\n",
    "- Sampling: **0.5 m** along-track  \n",
    "- Median window: **9 samples (4.5 m)**  \n",
    "- Mean window: **3 samples (1.5 m)**\n",
    "\n",
    "> Depths are negative (more negative = deeper). Filters operate the same.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick QC\n",
    "- Plot **raw vs despiked vs smoothed** together.  \n",
    "- Check **residual = raw − smoothed** to ensure mainly noise is removed.  \n",
    "- If over-smoothed → reduce window sizes; if spikes remain → increase the **median** window first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727d642-ea5a-47b6-affc-398964fd6ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Apply median filter to remove spikes\n",
    "window_size = 3  # Choose an odd number for the window size (e.g., 3, 5, 7)\n",
    "\n",
    "# Step 2: Apply rolling average to smooth the data further\n",
    "rolling_window = 3# Choose the rolling window size\n",
    "\n",
    "\n",
    "df['depth_despiked'] = medfilt(df['Depth_applied_elevation'], kernel_size=window_size)\n",
    "df['depth_smoothed'] = df['depth_despiked'].rolling(window=rolling_window, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c835e716-c8dc-441c-a756-7851f959442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['Depth_applied_elevation'], label = 'raw data')\n",
    "ax.plot(df['depth_despiked'], label = 'depth despiked')\n",
    "ax.plot(df['depth_smoothed'], label = 'depth smoothed')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f399c303-3706-4cda-9303-73fa215225a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Euclidean distances between consecutive points\n",
    "dx = df['East'].diff()\n",
    "dy = df['North'].diff()\n",
    "df['segment_dist'] = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "# First point has no previous point, so fill that with 0\n",
    "df['segment_dist'] = df['segment_dist'].fillna(0)\n",
    "\n",
    "# Cumulative distance from the start\n",
    "df['Distance'] = df['segment_dist'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6d1e8-004d-45a1-ad63-ffef0f7cd85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "ax.plot(df['Distance'], df['depth_smoothed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44cea8-c70c-4095-8748-cf1c42d3ebe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your two datasets are:\n",
    "df1 = pd.DataFrame()\n",
    "df1['distance'] = dflidar['Distance']\n",
    "df1['elevation'] = dflidar['Elevation']\n",
    "df2 = pd.DataFrame()\n",
    "df2['distance'] = dfsurv['Distance'] - 1.5\n",
    "df2['elevation'] = dfsurv['depth_despiked'] +0.65\n",
    "\n",
    "# Step 1: Define common distance range (e.g. from 0 to max distance)\n",
    "min_dist = max(df1['distance'].min(), df2['distance'].min())\n",
    "max_dist = min(df1['distance'].max(), df2['distance'].max())\n",
    "\n",
    "common_distances = np.arange(np.ceil(min_dist), np.floor(max_dist) + 1, 1)\n",
    "\n",
    "# Step 2: Interpolate both datasets to these distances\n",
    "interp1 = np.interp(common_distances, df1['distance'], df1['elevation'])\n",
    "interp2 = np.interp(common_distances, df2['distance'], df2['elevation'])\n",
    "\n",
    "# Step 3: Subtract interpolated elevations\n",
    "elevation_diff = interp2 - interp1\n",
    "\n",
    "# Step 4: Create a new DataFrame with results\n",
    "df_diff = pd.DataFrame({\n",
    "    'distance': common_distances,\n",
    "    'elevation_dataset1': interp1,\n",
    "    'elevation_dataset2': interp2,\n",
    "    'elevation_difference': elevation_diff\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae271df4-83f3-4c6a-80d1-6fc8e5050b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop=200\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_diff['distance'][start:stop], df_diff['elevation_difference'][start:stop], c= 'r', label = 'Difference')\n",
    "ax.plot(df_diff['distance'][start:stop], df_diff['elevation_dataset1'][start:stop], c= 'g', label = 'LiDAR bathymetry')\n",
    "ax.plot(df_diff['distance'][start:stop], df_diff['elevation_dataset2'][start:stop], c= 'b', label = 'Measured bathymetry (23/3/25)')\n",
    "ax.grid()\n",
    "ax.set_xlabel('Chainage (m)')\n",
    "ax.legend()\n",
    "ax.set_title('Groove infilling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f773ed0-1bc2-4cb9-b7ea-ac0bd3b16067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1e648-7217-46b7-bb7a-3b6dc06efa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop=200\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['distance'] = df_diff['distance'][start:stop]\n",
    "df['rastervalue'] = df_diff['elevation_dataset1'][start:stop]\n",
    "df['surveyvalue'] =  df_diff['elevation_dataset2'][start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f1a4d-cde4-4cfa-891f-c0973eae45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'2025_bathy_survey_example_data/forereef_survey_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea5c37-f85a-4ba0-83cc-e745d7de090d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_diff['elevation_difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c6cbb-0f78-4580-afb9-68d2bab819ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('250323_forereef_bathy_survey/forereef_survey_with_raster_vals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7950636-baec-4806-97a6-9a079f153913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Euclidean distances between consecutive points\n",
    "dx = dfsurv['East'].diff()\n",
    "dy = dfsurv['North'].diff()\n",
    "df['segment_dist'] = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "# First point has no previous point, so fill that with 0\n",
    "df['segment_dist'] = df['segment_dist'].fillna(0)\n",
    "\n",
    "# Cumulative distance from the start\n",
    "df['Distance'] = df['segment_dist'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be68d76-1265-485c-92a7-5ae6d5f9643e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8502b-fac0-463c-9868-db8510514e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective: minimise the absolute median elevation change\n",
    "def objective(offset):\n",
    "    elev_change = df['depth_despiked'] - (df['RASTERVALU'] - offset)\n",
    "    return abs(np.median(elev_change))\n",
    "\n",
    "# Run the optimisation\n",
    "result = minimize_scalar(objective, bounds=(-10, 10), method='bounded')  # Adjust bounds as needed\n",
    "\n",
    "print(result)\n",
    "print(\"\")\n",
    "# Best offset\n",
    "best_offset = result.x\n",
    "print(f\"Optimal offset: {best_offset:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb186e-a6a3-4089-a525-335bdc7a10cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "# Assume:\n",
    "# df['distance'] = original distance\n",
    "# df['depth_despiked'] = reference profile (e.g., survey)\n",
    "# df['RASTERVALU'] = comparison profile (e.g., DEM)\n",
    "\n",
    "# 1. Interpolate both profiles to a common grid\n",
    "common_dist = np.linspace(df['Distance'].min(), df['Distance'].max(), 500)\n",
    "\n",
    "# Reference: survey\n",
    "interp_ref = interp1d(df['Distance'], df['depth_despiked'], kind='linear', fill_value='extrapolate')\n",
    "ref_elev = interp_ref(common_dist)\n",
    "\n",
    "# Comparison: DEM\n",
    "interp_dem = interp1d(df['Distance'], df['RASTERVALU'], kind='linear', fill_value='extrapolate')\n",
    "\n",
    "# 2. Try a range of x-offsets (shifts)\n",
    "offsets = np.arange(-10, 10.1, 0.1)  # shift distances by ±10m in 0.1m steps\n",
    "rmse_values = []\n",
    "\n",
    "for offset in offsets:\n",
    "    shifted_dist = common_dist + offset\n",
    "    dem_elev = interp_dem(shifted_dist)\n",
    "    rmse = root_mean_squared_error(ref_elev, dem_elev)\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "# 3. Find best offset\n",
    "best_offset = offsets[np.argmin(rmse_values)]\n",
    "print(f\"Best x-offset: {best_offset:.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95468dc1-732a-42a5-8d36-e075449b3afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = 500\n",
    "stop = 600\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (10,8))\n",
    "ax.plot(df['Distance'][start:stop], df['depth_despiked'][start:stop],label = 'Echo sounder bathy (23/03/2025)')\n",
    "ax.plot(df['Distance'][start:stop], df['RASTERVALU'][start:stop], label = 'LiDAR bathy')\n",
    "ax.set_ylim(-7,0)\n",
    "#ax2 = ax.twinx()\n",
    "#ax2.grid()\n",
    "df['elev_change'] = df['depth_despiked'] - (df['RASTERVALU']-best_offset)\n",
    "ax.plot(df['Distance'][start:stop], df['elev_change'][start:stop], c= 'k', label = 'elevation change')\n",
    "ax.set_ylim(-7,2)\n",
    "ax.set_ylabel('elevation change')\n",
    "ax.set_ylabel('elevation')\n",
    "\n",
    "print(df['elev_change'].mean())\n",
    "ax.legend()\n",
    "ax.set_title('Groove infilling')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ff668-e7b6-4d56-83fd-8a5bf8db5f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Define the objective function: mean elevation change for a given offset\n",
    "def objective(offset):\n",
    "    elev_change = df['depth_despiked'] - (df['RASTERVALU'] - offset)\n",
    "    return abs(elev_change.mean())  # We want the mean to be as close to 0 as possible\n",
    "\n",
    "# Run the optimisation\n",
    "result = minimize_scalar(objective, bounds=(-10, 10), method='bounded')  # Adjust bounds as needed\n",
    "\n",
    "# Best offset\n",
    "best_offset = result.x\n",
    "print(f\"Optimal offset: {best_offset:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5030bf-7dde-42da-9a92-f6d580f994ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
